\chapter{Introduction}

Knowledge of DNA sequences has become indispensable for basic biological research
and in numerous applied fields like diagnostics, forensic biology, etc.
It is also important for understanding cancer, fighting antibiotic resistant bacteria, etc.
With decreasing cost of DNA sequencing we are able to sequence more organisms,
but consequently we have to handle much bigger amounts of data. 

Unfortunately, we are still not able to read whole DNA sequence at one, we can only
read it in small pieces and then rely on computational methods of sequence assembly
to produce whole DNA sequence.

In this work, we describe theoretical background of sequence assembly,
current algorithms and heuristics used in practice and also related 
problems of evaluating quality of sequence assembly.

In the rest of this chapter, we describe basics of sequence assembly,
several real life complications and provide basic overview of theoretical
formulations and practical algorithms used for sequence assembly.

The second chapter is decicated to de Bruijn graphs, which
are important data structures in sequence assembly and has many other
applications in processing DNA sequences.

In the third chapter, we discuss various approaches for evaluating
quality of the resulting assembly and comparing assemblies.

The fourth chapter contains our PhD project where we
shortly describe one of our papers and provide multiple
options for future research.

\section{Problem of the Sequence Assembly}

For the purpose of this work we can view DNA sequence as a string over the
four letter alphabet A, C, G, T. The usual length of these strings
is between millions and billions of characters.
Current technologies cannot read the whole sequence at once, instead they produce many
overlapping substrings of sequence called reads.
In most cases locations of these substrings are sampled uniformly.
The goal of sequence assembly is to reconstruct original string.

Perhaps the oldest formulation of this task as a computer science
problem is the shortest common supersting problem:

\begin{definition}[Shortest common supersting]
Given set of strings $\mathcal{P} = \{S_1, S_2, \dots, S_k\}$, the shortest
common superstring is a shortest string $S$, that contains every string
from $\mathcal{P}$ as a substring.
\end{definition}

But unfortunately, finding shortest common superstring is NP-hard \citep{SCShard}.
There is a known $2.5$-approximation algorithm \citep{SCSapx}.
The most common greedy heuristic for this problem is:
\begin{verbatim}
When there is more than one string:
  Merge two strings with largest overlap
\end{verbatim}

The approximation factor for this heuristic is not known. There are inputs
which produce string which are two times longer than optimal
and it is conjectured that this bound is tight.

\medskip

Over the years, it has been shown
that this formuation does not represent the underlying problem very well.
On one hand, the problem is difficult to solve computationally, and the
approximation algorithms do not yield very practical results.
On the other hand, this formulation does not consider some specifics of the underlying data.
For example consider following DNA sequence:

$$AA\textcolor{red}{CGTA}\textcolor{green}{CGTA}\textcolor{blue}{CGTA}GG$$

If we have reads of length four that come from all possible positions, the shortest
common superstring would be:

$$AA\textcolor{red}{CGTA}\textcolor{green}{CGTA}GG$$

We have lost one repetition of repeated sequence. Such repeated sequences are
very common in real DNA sequences \citep{DNARep}.

%If we assume uniform
%sampling from original sequence we might estimate the number of repeated substring
%by using coverage information (how many reads cover one position).

But there are also sequences for which it is impossible to even 
reconstruct the order of elements
in the original sequence. For example in the sequence:

$$AA\textcolor{red}{CTCT}\textcolor{green}{GG}\textcolor{red}{CTCT}\textcolor{blue}{CC}\textcolor{red}{CTCT}TT$$

With reads of length four, we cannot distinguish between this original sequence and
the sequence:

$$AA\textcolor{red}{CTCT}\textcolor{blue}{CC}\textcolor{red}{CTCT}\textcolor{green}{GG}\textcolor{red}{CTCT}TT$$

Due to these problems it is obvious that finding shortest common supersting
is not a good formulation for sequence assembly. 
In practice our goals are usually more humble and we are satisfied with reconstructing
umambigous parts of the DNA sequence. Assembly tools
usually produce substrings from the original sequence called {\bf contigs}.
Sometimes they are also able to detect approximate distance between contigs
(but cannot infer DNA sequence between them), so they join
contigs into scaffolds. {\bf Scaffold} is a sequence of contigs with known
approximate distance between them. 
This unknown areas are ofter represented as a strings of several $N$-s.

We will discuss several attempts of theoretical assembly formulation in
next sections but first we look into more complications of sequence assembly.

\subsection{Real-life Complications}

In practice, there are several complications which make the sequence assembly even harder.
In the following text we mention the major ones.

\paragraph{Reverse complement.} 
The DNA comes in two strands, which are reverse complements to each other.

\begin{definition}[Reverse complement]
For given DNA sequence $S$, its reverse complement is defined as
$RC(S) = h(S^R)$, where $h(\cdot)$ is a homomorphism where $h(A) = T, h(C) = G,
h(G) = C, h(T) = A$. 
\end{definition}

During sequencing we sequence both strands of the DNA and we do not have
any information about read orientation (which strand the read comes from).

\paragraph{Diploid genomes.}
Many organisms have multiple sets of chromosomes. For example humans have one set
inherited from the mother and other set inherited from the father, so each chromosome
is present in two copies. This two copies of each chromosome are almost identical but
contain some differences (sometimes only changes in one base, but sometimes also
bigger variations). This poses additional chanllenge since we are trying to recostruct
multiple similar sequences.

\paragraph{Errors in reads.}
In practice the chemical process of sequencing DNA also produces errors.
Sometimes there are small errors in reads, i.e. substitutions, insertions
and deletions. The amount of these errors depend on specific sequencing technology.
For example some technologies have higher amount of substitutions while others
have high amount of insertions. 
There are also reads which do not belong to the sequenced genome, but are result
of a contamination.

\paragraph{Paired reads}
Some technologies produces reads in pairs for which we know appoximate distance
in the genome. The total length of reads plus approximate distance between reads
is called {\bf insert size}.

\subsection{Sequencing Technologies}

There are several sequecing technologies currently available. They vary
in many properties like cost, read length, accuracy, etc.
We summarize currently used sequencing technologies in Table \ref{tab:techs},
based on data from \citet{seq1,seq2}.
We also added statistics of old Sanger sequencing for comparison.

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multirow{2}{*}{Technology} & Read   & Error & Paired & Cost per      & Reads   & Time \\
                            & length & rate  & reads  & million bases & per run & per run \\\hline
Sanger & 900 & $0.1\%$ & Yes & $\$2400$ & N/A & few hours\\\hline
454 & 700 & $0.1\%$ & Yes & $\$10$ & 1 million & one day\\\hline
Illumina & 50 - 300 & 2\% & Yes & $\$0.05 - \$0.15$ & up to 3 billion & few days\\\hline
PacBio & 20000 & $14\%$ & No & $\$0.13 - \$0.60$ & 50000 & few hours\\\hline
\end{tabular}
\caption{Overview of current sequencing technologies}
\label{tab:techs}
\end{table}

Wide variety of technologies present additional challenge to assembly software.
They have to handle multiple combinations of reads libraries from possibly
different technologies (like Illumina + PacBio,
or multiple libraries of Illumina reads with different insert sizes).
We will discuss this topic further in section about assembly algorithms. 

\section{Overview of Current Solutions}

We will now discuss several better attempts at theoretical
formulation of sequence assembly and then we will describe currently
used assembly algorithms.

\subsection{Formalization of the Assembly Problem}

To sum up previous sections, we are trying to reconstruct DNA seqence from reads,
which:
\begin{itemize}
\itemsep-0pt
\item Are much smaller than original sequence.
\item Have unknown orientation.
\item Contain errors.
\item Some of them are not from the original sequence.
\item Might be paired. 
\end{itemize}

\bigskip

To account for the possibility of sequencing errors, 
\citet{kececioglu1995combinatorial}
proposed a variant of shortest common supersting problem. 

\begin{definition}{Shortest common superstring with errors.}
Given set of reads $\mathcal{F}$ and error rate $\varepsilon$, find
a shortest sequence $S$ such that for every $A \in \mathcal{F}$ there is a substring
$B$ of $S$ such that:
$$min(d(A,B), d(\bar{A}, B)) \leq \varepsilon |A|$$
\end{definition}

This formulation can be also extended to account for contaminated reads and paired reads.
While accounting for sequencing errors, this formulation is still problematic
since it compresses repeated regions in the genome.
Not surprisingly, this problem is NP-hard \citep{kececioglu1991exact}.

\bigskip

One way of estimating the number of repeats regions is to observe
that if we collapse some repeated regions there we will see far
more reads coming from collapsed regions that from others. 

This is used in formulation given by \citet{myers1995toward}. It considers
coverage of the output sequence by reads and wants it to be as uniform as possible.

We consider our reconstructed string $S$ and the positions of reads (layout)
consisting of $F$ pairs of integers $(s_i, e_i)$,
\ which indicates starting and ending positions
of reads in the reconstructed sequence. The layout is $\varepsilon$-valid
if for each read $A$, the edit distance between $S[s_i:e_i]$ and the read
is at most $\varepsilon |A|$.

We will now formalize the notion of uniform coverage. Lets consider a observed
distribution of read start points (the proportion of reads which start before $x$):
$$D_{obs}(x) = \frac{|\{s_i < x\}|}{F}$$

We now consider a source distribution of a sampling process $D_{src}$ (which is usually
uniform, but can be nonuniform due to some systematic errors) and define maximum
deviation between these two distributions:
$$\delta = max |D_{obs}(x) - D_{src}(x)|$$

Now we can define DNA sequence reconstruction problem in a better way:

\begin{definition}{DNA sequence reconstruction problem.}
Given set of reads $\mathcal{F}$ and error rate $\varepsilon$, find
a sequence $S$ and $\varepsilon$-valid layout which has minimal
maximum deviation between observed and source distrition of reads.
\end{definition}

There are none theoretical results known to us about this formulation
(the original paper focuses more on devoloping branch-and-bound algorithm
than on theoretical results about NP-hardness and approximation).
But we suspect that it is also NP-hard as others.

There are still some ambiguities and problems with this formulation.
One can for example find two solutions which have the same maximum deviation
but differ in one base.
Also this formulation can be extended to account for contaminated and paired
reads.

Nevertheless, these formulations have never been used to design
a pracical sequence assembler, because they exact solutions are too slow
and approximate solutions are not good for practice.

More popular approach is to design heuristic solutions, which we describe in the next
section.

\subsection{Assembly Algorithms Overview}

Almost all assembly algorithms used in practice are some form of heuristics
without well defined formulation, proof of correctness, etc.
%There are well defined algorithms, for example algorithm by \cite{Medvedev2009}
%which uses bidirectional flows, but they practical use is very limited (this one
%assumes error-free reads).
In general, these heuristics proceed to "glue" reads which can be
unambiguously glued together and building assembly step by step
without following clear optimalization criteria.
They use efficient representation of overlaps between reads and try to resolve
ambiguous regions using paired reads and long reads.

The good review of assembly algorithms can be found in \citet{miller2010assembly}.
They can be divided into two types by representation of overlaps they use.

\paragraph{Overlap-layout-consensus algorithms.}
The overlap-layout-consensus (OLC) algorithms use overlap graph, which directly represents
overlaps between reads (two reads are connected by edge, if there is a sufficiently long overlap between them). It was first suggested by \citet{myers1995toward}.
To produce this graph we need to find sufficiently long
overlaps between all reads (and this overlap not need to be exact, we usually allow small edit distance between overlapping parts). This often leads to algorithms which have quadratic
complexity to the number of reads (but can be often speeded up by various heuristics).

After finding overlaps we usually perform removing of transitive edges (we remove edge
from $u$ to $w$ if there is an vertex $v$ and edges from $u$ to $v$ and from $v$ to $w$).
In the layout step we try to find reasonable layout of reads in the assembly.
Assemblers usually start by joining reads which can be joined unambiguosly (i.e.
when read $u$ is only one following read $v$ and $v$ is only one preceeding $u$).
and then use information from paired reads to resolve areas around repeats.

Finally, in consensus step we perform base calling, e. g. if 10 reads overlap in
one possitions and 9 of them says the base should be $A$ and one says $G$ we decide the base to
be $A$.

Typical example of OLC algorithm is Celera \citep{Celera}.
It was mainly used for assembling of Sanger reads. But the OLC
framework was not suitable for assembling Illumina reads due to large number
of rather short reads (three to ten times shorter than Sanger reads), which
would dramaticaly increase the number of overlaps. 
The OLC algorithms has gained popularity after introducing PacBio reads
which have much higher length (so we have fewer reads) but much higher error rate.
Due to high error rate, the overlap phase is quite challenging, but
doable with careful implementation \citep{myers2014efficient}. 

\paragraph{De Bruijn graphs.}
The other algorithms use de Bruijn graphs, which do not work directly with reads, but
with sequences of $k$-bases ($k$-mers) which occur in reads. The nodes in de Bruijn graph represent $k$-mers
and edges represent adjacencies between $k$-mers in reads. Note that time
required to construct this graph is linear in the length of reads, but on the other hand
we lose some information since we are not working with whole reads.
After constructing de Bruijn graph we can join $k$-mers which be
unambiguously joined and then apply various heuristics for resolving repeats.
We will describe de Bruijn graphs in more detail in the next chapter.
Typical example of de Bruijn assembler is Velvet \citep{Velvet}.

\bigskip

There are some more technical aspects of the assembly software.
Some assemblers like AbySS \citep{Abyss} allow distributed computing
of assembly. Also lots of assemblers
have some special requirements for input data. For example
Allpaths \citep{allpaths} requires two Illumina read libraries, one
with small insert size (apx. $150$ bases) and one with longer insert
size (apx. $3000$ bases), but optionally can use information from other libraries
(paired read with even longer insert size or PacBio reads).

\section{Summary}

In this chapter we provided basic overview of sequenced assembly problem
and its real life complications (reverse complements, errors in reads,
diploid genomes, paired reads, multiple technologies). 
We showed that the sequence assembly problem is hard to formulate
as a typical computer science problem (with clear notion of output and objective function)
and showed some attempts for its formulation.
We discussed several practical approaches for sequence assembly problem like
overlap-layout-consensus framework and de Bruijn graphs.
