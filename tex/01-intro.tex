\chapter{Introduction}

TODO celkovy uvod

\section{Problem of the Sequence Assembly}

For the purpose of this work we can view DNA sequence as a string over the
four letter alphabet A, C, G, T. The usual length of these strings
is between millions and billions of characters.
Current technologies cannot read the whole sequence at once, instead they produce many
overlapping substrings of sequence called reads.
In most cases locations of these substrings are sampled uniformly.
The goal of sequence assembly is to reconstruct original string.

Perhaps the oldest formulation of this task as a computer science
problem is the shortest common supersting problem:

\begin{definition}{Shortest common supersting.}
Given set of strings $\mathcal{P} = \{S_1, S_2, \dots, S_k\}$, the shortest
common superstring is a shortest string $S$, that contains every string
from $\mathcal{P}$ as a substring.
\end{definition}

But unfortunately, finding shortest common superstring if NP-hard (\cite{SCShard}).
There is a known $2.5$-approximation algorithm (\cite{SCSapx}).
The most common greedy heuristic for this problem is:
\begin{verbatim}
Where there is more than one string:
  Merge two strings with largest overlap
\end{verbatim}

The approximation factor for this heuristic is not known. There are inputs
which produce string which are two times longer than optimal
and it is conjectured that this bound is tight.


Over the years, it has been shown
that this formuation does not represent the underlying problem very well.
On one hand, the problem is difficult to solve computationally, and the
approximation algorithms do not yield very practical results.
On the other hand, this formulation does not consider some specifics of the underlying data.
For example consider following DNA sequence:

$$AA\textcolor{red}{CGTA}\textcolor{green}{CGTA}\textcolor{blue}{CGTA}GG$$

If we have reads of length four that come from all possible positions, the shortest
common superstring would be:

$$AA\textcolor{red}{CGTA}\textcolor{green}{CGTA}GG$$

We have lost one repetition of repeated sequence. Such repeated sequences are
very common in real DNA sequences (see \cite{DNARep}).

%If we assume uniform
%sampling from original sequence we might estimate the number of repeated substring
%by using coverage information (how many reads cover one position).

But there are also sequences for which it is impossible to even 
reconstruct the order of elements
in the original sequence. For example in the sequence:

$$AA\textcolor{red}{CTCT}\textcolor{green}{GG}\textcolor{red}{CTCT}\textcolor{blue}{CC}\textcolor{red}{CTCT}TT$$

With reads of length four, we cannot distinguish between this original sequence and
the sequence:

$$AA\textcolor{red}{CTCT}\textcolor{blue}{CC}\textcolor{red}{CTCT}\textcolor{green}{GG}\textcolor{red}{CTCT}TT$$

Due to this, the goal of the sequence assembly is to reconstruct as long as possible
unambiguous parts of the DNA sequence (called contigs).
TODO rozpisat

%\section{Real-life complications}

In practice, there are several complications which make the sequence assembly even harder.
In the following text we mention the major ones.

\paragraph{Reverse complement.} 
The DNA comes in two strands, which are reverse complementes to each other.

\begin{definition}{Reverse complement}
For given DNA sequence $s$ its reverse complement is defined as
$RC(s) = h(s^R)$, where $h(\cdot)$ is a homomorphism where $h(A) = T, h(C) = G,
h(G) = C, h(T) = A$. 
\end{definition}

During sequencing we sequence both strands of the DNA and we do not have
any information about read orientation (which strand the read comes from).

\paragraph{Diploid genomes.}
Many organisms have multiple sets of chromosomes. For example humans have one set
inherited from the mother and other set inherited from the father, so each chromosome
is present in two copies. This two copies of each chromosome are almost identical but
contain some differences (sometimes only changes in one base, but sometimes also
bigger variations). This poses additional chanllenge since we are trying to recostruct
multiple similar sequences.
TODO ako caste zmeny

\paragraph{Errors in reads.}
In practice the chemical process of sequencing DNA also produces errors.
Sometimes there are small errors in reads, i.e. substitutions, insertions
and deletions. The amount of these errors depend on specific sequencing technology.
For example some technologies have higher amount of substitutions while others
have high amount of insertions. 
There are also reads which do not belong to the sequenced genome, but are result
of a contamination.

\paragraph{Paired-end reads}
Some technologies start reading fragments from one end and lose accuracy after
reading few hundred bases. To capture information which contains longer part of the
sequence some technologies produce longer fragments from which they readtens to hundreds
of bases from both sides and do not read bases from middle (since there will be
too many errors). The result of this process is a pair of reads for which we know approximate
distance in the DNA sequence. This distance is often called insert size.

\subsection{Sequencing technologies}

We summarize currently used sequencing technologies in \ref{tab:techs}.
This presents additional chalenge for assembling algorithms since they
cannot be tailored only for one technology, but should work with combination
of data from many technologies.

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Technology & Read length & Error rate & Paired end reads \\\hline
Illumina & 50 - 300 & 2\% & Yes\\\hline
454 & 700 & $0.1\%$ & Yes \\\hline
PacBio & 2000 - 20000 & $14\%$ & No \\\hline
\end{tabular}
\caption{Overview of current sequencing technologies}
\label{tab:techs}
\end{table}

Also note that it is much cheaper to produce paired reads with lower insert sizes,
so it is common to combine multiple libraries such as high coverage reads with low insert size
(e.g. 200 bases), and lower coverage reads with high insert size (e.g. 3000 bases).

\section{Overview of known solutions}

\subsection{Assembly problem formalization}

There are several formulations of the genome assembly problem, but
most of them are not user in practice.

First of them is a variation of shortest common superstring problem, where we
almost account for the possibility of sequencing errors \cite{kececioglu1995combinatorial}. 

\begin{definition}{DNA sequence reconstruction problem 1.}
Given set of reads $\mathcal{F}$ and error rate $\varepsilon$, find
a shortest sequence $S$ such that for every $A \in \mathcal{F}$ there is a substring
$B$ of $S$ such that:
$$min(d(A,B), d(\bar{A}, B)) \leq \varepsilon |A|$$
\end{definition}

This formulation can be also extended to account for contaminated reads and paired reads.
As mentioned above this formulation is problematic since it compresses repeated regions
in the genome.

A better formulation is given by \cite{myers1995toward}. It also considers
coverage of output sequence by substring and wants it to be as uniform as possible.

We consider our reconstructed string $S$ and the layout consisting of
$F$ pairs of integers $(s_i, e_i)$, which indicates starting and ending positions
of reads in the reconstructed sequence. The layout is $\varepsilon$-valid
if for each read $A$ the edit distance between $S[s_i:e_i]$ and the read
is at most $\varepsilon |A|$.

We will now formalize the notion of uniform coverage. Lets consider a observed
distribution of read start points (the proportion of reads which start before $x$):
$$D_{obs}(x) = \frac{|\{s_i < x\}|}{F}$$

We now consider a source distribution of a sampling process $D_{src}$ (which is usually
uniform, but can be nonuniform due to some systematic errors) and define maximum
deviation between these two distributions:
$$\delta = max |D_{obs}(x) - D_{src}(x)|$$

Now we can define DNA sequence reconstruction problem in a better way:

\begin{definition}{DNA sequence reconstruction problem 2.}
Given set of reads $\mathcal{F}$ and error rate $\varepsilon$, find
a sequence $S$ and $\varepsilon$-valid layout which has minimal
maximum deviation between observed and source distrition of reads.
\end{definition}

There are still some ambiguities and problems with this formulation.
One can for example find two solutions which have same maximum deviation
but differ in one base.
Also this formulation can be extended to account for contaminated and paired
reads.

\subsection{Assembly algorithms overview}

Almost all assembly algorithms used in practice are some form of heuristics
without well defined formulation, proof of correctness, etc.
There are well defined algorithms, for example algorithm by \cite{Medvedev2009}
which uses bidirectional flows, but they practical use is very limited (this one
assumes error-free reads).

The goal of assembly algorithms is to "glue" reads which can be unambiguously glued together.
They use efficient representation of overlaps between reads and try to resolve
ambiguous regions using paired end reads and long reads.

The good review of assembly algorithms can be found in \cite{miller2010assembly}.
They can be divided into two types by representation of overlaps they use.

The overlap-layout-consensus algorithms use overlap graph, which directly represents
overlaps between reads (two reads are connected by edge, if there is a sufficiently long overlap between them).
To produce this graph we need to find sufficiently long
overlaps between all reads (and this overlap not need to be exact, we usually allow small edit distance between overlapping parts).
This often leads to algorithms which have quadratic
complexity to the number of reads (but can be often speeded up by various heuristics).
After finding overlaps we usually perform removing of transitive edges (we remove edge
from $u$ to $w$ if there is an vertex $v$ and edges from $u$ to $v$ and from $v$ to $w$).

In the layout step we try to find reasonable layout of reads in the assembly.
Finally, in consensus step we perform base calling, e. g. if 10 reads overlaps in
one possitions and 9 of them says the base should be $A$ and one says $G$ we decide the base to
be $A$.

\medskip

The other algorithms use De Bruijn graphs, which do not work directly with reads, but
with sequences of $k$-bases ($k$-mers). The nodes in De Bruijn graph represent $k$-mers
and edges represent adjacencies between $k$-mers in reads. Note that time
required to construct this graph is linear in the length of reads, but on the other hand
we lose some information since we are not working with whole reads.
